{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n# Análisis predictivo de FRR — KDF‑11 (Random Forest, validación y simulaciones)\n\nEste cuaderno entrena **modelos de bosques aleatorios (Random Forest)** para predecir el **% de FRR por causa** (`faltante`, `extra`, `roto`, `posicion`) a partir de los parámetros de la KDF‑11, valida con **k-fold**, genera **importancias de variables** y permite **simulaciones** de tipo “¿qué pasa si cambio X y dejo todo lo demás igual?”.\n\n**Archivo de entrada:** `FRR-11.xlsx`\n\n> Autor: Francisco Tinoco + Copilot  \n> Fecha de generación: 2025-12-05 17:19\n    "
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# %% [markdown]\n# ## 1. Imports, configuración y verificación del entorno\n\nimport os\nimport math\nimport json\nimport warnings\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Para modelado y validación\ntry:\n    from sklearn.ensemble import RandomForestRegressor\n    from sklearn.model_selection import KFold, cross_validate\n    from sklearn.inspection import permutation_importance\n    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n    SKLEARN_OK = True\nexcept Exception as e:\n    SKLEARN_OK = False\n    print(\"Aviso: scikit-learn no está disponible. Instálalo con: !pip install scikit-learn\")\n    print(\"Error de importación:\", e)\n\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8')\nnp.set_printoptions(suppress=True)\n\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\n# Directorios\nDATA_PATH = Path('FRR-11.xlsx')\nOUTPUT_DIR = Path('salidas_modelo')\nOUTPUT_DIR.mkdir(exist_ok=True)\nprint(f\"Directorio de salida: {OUTPUT_DIR.resolve()}\")\n    "
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# %% [markdown]\n# ## 2. Carga de datos y normalización de columnas\n\nimport unicodedata\n\ndef normalize_col(name: str) -> str:\n    \"\"\"Normaliza nombres de columnas: minúsculas, sin acentos, sin puntuación y espacios a guiones bajos.\"\"\"\n    if name is None:\n        return ''\n    s = str(name).strip().lower()\n    # quita acentos\n    s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n    # reemplazos específicos frecuentes\n    s = s.replace('/', '_').replace('\\', '_').replace('.', ' ').replace('#', 'num')\n    s = s.replace('%', 'pct')\n    # colapsa espacios a guion bajo\n    s = '_'.join(s.split())\n    return s\n\n# Mapas de sinónimos -> objetivo canónico\nCOL_MAP = {\n    'fecha': 'fecha',\n    'num': 'num',\n    'rv2': 'rv2',\n    'rv4': 'rv4',\n    'rv5': 'rv5',\n    'rv6': 'rv6',\n    'lim_max': 'lim_max',\n    'lim_min': 'lim_min',\n    'v3_kdf': 'v3_kdf',\n    'v2_v3': 'v2_v3',\n    'presion': 'presion',\n    'angulo': 'angulo',\n    'posision': 'posicion',   # manejo de typo frecuente\n    'posicion': 'posicion',\n    'vel': 'vel',\n    'min': 'min',\n    'min_': 'min',\n    'faltante_frr': 'frr_faltante',\n    'extra_frr': 'frr_extra',\n    'roto_frr': 'frr_roto',\n    'posicion_frr': 'frr_posicion',\n    'total': 'frr_total'\n}\n\n# Candidatos de features y targets esperados (canónicos)\nFEATURES_WISHLIST = ['rv2','rv4','rv5','rv6','lim_max','lim_min','v3_kdf','v2_v3','presion','angulo','posicion','vel','min']\nTARGETS_WISHLIST = ['frr_faltante','frr_extra','frr_roto','frr_posicion']\n\n# Leer Excel y detectar hoja con mejores columnas\nxls = pd.ExcelFile(DATA_PATH, engine='openpyxl')\nprint('Hojas detectadas:', xls.sheet_names)\n\nbest_df = None\nbest_score = -1\nbest_sheet = None\n\nfor sheet in xls.sheet_names:\n    df0 = pd.read_excel(xls, sheet_name=sheet)\n    raw_cols = list(df0.columns)\n    norm_cols = [normalize_col(c) for c in raw_cols]\n    # aplica mapa de sinónimos\n    mapped_cols = [COL_MAP.get(c, c) for c in norm_cols]\n    df0.columns = mapped_cols\n    # puntúa por cantidad de columnas esperadas presentes\n    score = sum(1 for c in FEATURES_WISHLIST+TARGETS_WISHLIST+['frr_total'] if c in df0.columns)\n    if score > best_score:\n        best_score = score\n        best_df = df0.copy()\n        best_sheet = sheet\n\nassert best_df is not None, \"No se pudo cargar ninguna hoja con columnas esperadas. Revisa el archivo.\"\nprint(f\"Se usará la hoja: {best_sheet} (score columnas={best_score})\")\n\n# Vista previa\ntry:\n    display(best_df.head())\nexcept Exception:\n    print(best_df.head())\nprint(\"Columnas normalizadas:\")\nprint(sorted(best_df.columns))\n\n# Chequeo de consistencia: suma de causas vs total (si existe)\nif set(TARGETS_WISHLIST).issubset(best_df.columns) and 'frr_total' in best_df.columns:\n    suma_causas = best_df[['frr_faltante','frr_extra','frr_roto','frr_posicion']].sum(axis=1)\n    dif = (best_df['frr_total'] - suma_causas)\n    print('\nResumen coherencia (Total ≈ suma de causas):')\n    print('Dif media:', float(dif.mean()))\n    print('Dif std  :', float(dif.std()))\n    print('Dif min  :', float(dif.min()))\n    print('Dif max  :', float(dif.max()))\n    "
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# %% [markdown]\n# ## 3. Preparación de features (X) y objetivos (Y)\n\n# Filtramos columnas disponibles\nfeatures = [c for c in FEATURES_WISHLIST if c in best_df.columns]\nmissing_feat = [c for c in FEATURES_WISHLIST if c not in features]\n\ntargets = [c for c in TARGETS_WISHLIST if c in best_df.columns]\nmissing_tgt = [c for c in TARGETS_WISHLIST if c not in targets]\n\nprint('Features usados (X):', features)\nprint('Targets usados (Y):', targets)\nif missing_feat:\n    print('Aviso: Faltan en el archivo estas features esperadas:', missing_feat)\nif missing_tgt:\n    print('Aviso: Faltan en el archivo estos targets esperados:', missing_tgt)\n\n# Copiamos X e Y\nX = best_df[features].copy()\nY = best_df[targets].copy()\n\n# Casting numérico y manejo de NaN\nfor c in X.columns:\n    X[c] = pd.to_numeric(X[c], errors='coerce')\nfor c in Y.columns:\n    Y[c] = pd.to_numeric(Y[c], errors='coerce')\n\n# Eliminamos filas con NaN en X o Y (alternativa: imputación)\nmask_ok = X.notna().all(axis=1) & Y.notna().all(axis=1)\nX = X[mask_ok].reset_index(drop=True)\nY = Y[mask_ok].reset_index(drop=True)\nprint(f\"Filas tras limpieza: {len(X)}\")\n\n# Guardamos dataset limpio (opcional)\nX.join(Y).to_excel(OUTPUT_DIR / 'dataset_limpio.xlsx', index=False, engine='openpyxl')\nprint('Dataset limpio exportado a: salidas_modelo/dataset_limpio.xlsx')\n    "
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# %% [markdown]\n# ## 4. Entrenamiento con Random Forest por causa (k-fold cross-validation)\n\nif not SKLEARN_OK:\n    raise SystemExit('scikit-learn es requerido para continuar.')\n\nk = 5\ncv = KFold(n_splits=k, shuffle=True, random_state=RANDOM_STATE)\n\nmodelos: Dict[str, RandomForestRegressor] = {}\ncv_resultados: Dict[str, dict] = {}\n\nfor target in targets:\n    y = Y[target].values\n    rf = RandomForestRegressor(\n        n_estimators=400,\n        max_depth=10,\n        min_samples_leaf=3,\n        random_state=RANDOM_STATE,\n        n_jobs=-1,\n    )\n\n    scoring = {\n        'MAE': 'neg_mean_absolute_error',\n        'RMSE': 'neg_root_mean_squared_error',\n        'R2': 'r2'\n    }\n\n    scores = cross_validate(rf, X.values, y, cv=cv, scoring=scoring, return_train_score=False)\n\n    res = {\n        'MAE_mean': -scores['test_MAE'].mean(),\n        'MAE_std' :  scores['test_MAE'].std(),\n        'RMSE_mean': -scores['test_RMSE'].mean(),\n        'RMSE_std' :  scores['test_RMSE'].std(),\n        'R2_mean': scores['test_R2'].mean(),\n        'R2_std' : scores['test_R2'].std(),\n    }\n\n    cv_resultados[target] = res\n\n    # Entrenamos modelo final en todo el dataset\n    rf.fit(X.values, y)\n    modelos[target] = rf\n\n# Mostrar resultados\nprint('Métricas k-fold (menor es mejor en MAE/RMSE):\n')\nres_df = pd.DataFrame(cv_resultados).T\ntry:\n    display(res_df)\nexcept Exception:\n    print(res_df)\nres_df.to_excel(OUTPUT_DIR / 'metricas_cv.xlsx', engine='openpyxl')\nprint('Métricas exportadas a: salidas_modelo/metricas_cv.xlsx')\n    "
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# %% [markdown]\n# ## 5. Importancia de variables (Gini) y Permutation Importance\n\nfig, axes = plt.subplots(len(targets), 2, figsize=(12, 4*len(targets)), constrained_layout=True)\nif len(targets) == 1:\n    axes = np.array([axes])\n\nfor i, target in enumerate(targets):\n    rf = modelos[target]\n    # Importancia por impureza (Gini)\n    imp = pd.Series(rf.feature_importances_, index=features).sort_values(ascending=False)\n    imp.plot(kind='bar', ax=axes[i,0], color='#1f77b4')\n    axes[i,0].set_title(f\"Importancia (Gini) — {target}\")\n    axes[i,0].set_ylabel('Importancia')\n    axes[i,0].grid(axis='y', alpha=0.3)\n\n    # Permutation importance sobre el conjunto completo (aprox.)\n    pi = permutation_importance(rf, X.values, Y[target].values, n_repeats=20, random_state=RANDOM_STATE, n_jobs=-1)\n    pi_mean = pd.Series(pi.importances_mean, index=features).sort_values(ascending=False)\n    pi_std  = pd.Series(pi.importances_std, index=features).loc[pi_mean.index]\n    axes[i,1].bar(pi_mean.index, pi_mean.values, yerr=pi_std.values, color='#ff7f0e', alpha=0.9, capsize=3)\n    axes[i,1].set_title(f\"Permutation importance — {target}\")\n    axes[i,1].set_ylabel('Δ score (RMSE aprox.)')\n    axes[i,1].tick_params(axis='x', rotation=45)\n    axes[i,1].grid(axis='y', alpha=0.3)\n\nplt.suptitle('Importancia de variables por causa', y=1.02, fontsize=14)\nplt.savefig(OUTPUT_DIR / 'importancias_variables.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint('Gráfica guardada en: salidas_modelo/importancias_variables.png')\n    "
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# %% [markdown]\n# ## 6. Simulaciones “¿qué pasa si…?” variando un parámetro\n\nfrom dataclasses import dataclass\n\n@dataclass\nclass SimulacionResultado:\n    feature: str\n    valores: np.ndarray\n    preds: pd.DataFrame  # columnas = targets\n\n\ndef simular_parametro(fila_ref: pd.Series, feature: str, valores: np.ndarray) -> SimulacionResultado:\n    \"\"\"Simula variando una sola feature y predice FRR por causa con los modelos entrenados.\"\"\"\n    if feature not in X.columns:\n        raise ValueError(f\"La feature '{feature}' no está en X. Features disponibles: {list(X.columns)}\")\n\n    base = fila_ref.copy()\n    grid = []\n    for v in valores:\n        row = base.copy()\n        row[feature] = v\n        grid.append(row.values)\n\n    grid = np.array(grid)\n    pred_dict = {}\n    for target in targets:\n        pred = modelos[target].predict(grid)\n        pred = np.clip(pred, 0, 100)  # límites lógicos 0-100\n        pred_dict[target] = pred\n\n    preds_df = pd.DataFrame(pred_dict)\n    return SimulacionResultado(feature=feature, valores=valores, preds=preds_df)\n\n\ndef graficar_simulacion(sim_res: SimulacionResultado, titulo: str = None):\n    plt.figure(figsize=(8,5))\n    for col, color in zip(sim_res.preds.columns, ['#1f77b4','#ff7f0e','#2ca02c','#d62728']):\n        plt.plot(sim_res.valores, sim_res.preds[col], label=col, linewidth=2, color=color)\n    plt.xlabel(sim_res.feature)\n    plt.ylabel('% FRR predicho')\n    plt.grid(alpha=0.3)\n    plt.legend(title='Causa')\n    if not titulo:\n        titulo = f\"Simulación variando '{sim_res.feature}'\"\n    plt.title(titulo)\n    plt.tight_layout()\n\n# Elegimos una fila de referencia (la última por defecto)\nref = X.iloc[-1]\nprint('Fila de referencia (última observación):')\ntry:\n    display(ref.to_frame().T)\nexcept Exception:\n    print(ref.to_frame().T)\n\n# Ejemplo 1: variar Presión\nif 'presion' in X.columns:\n    a = X['presion'].min()\n    b = X['presion'].max()\n    vals_pres = np.linspace(a, b, 25)\n    sim1 = simular_parametro(ref, 'presion', vals_pres)\n    graficar_simulacion(sim1, 'Efecto de variar Presión en %FRR por causa')\n    plt.savefig(OUTPUT_DIR / 'sim_presion.png', dpi=150, bbox_inches='tight')\n    plt.show()\nelse:\n    print(\"Columna 'presion' no disponible; omitiendo simulación de presión.\")\n\n# Ejemplo 2: variar Posición (si existe)\nif 'posicion' in X.columns:\n    a = X['posicion'].quantile(0.05)\n    b = X['posicion'].quantile(0.95)\n    vals_pos = np.linspace(a, b, 25)\n    sim2 = simular_parametro(ref, 'posicion', vals_pos)\n    graficar_simulacion(sim2, 'Efecto de variar Posición en %FRR por causa')\n    plt.savefig(OUTPUT_DIR / 'sim_posicion.png', dpi=150, bbox_inches='tight')\n    plt.show()\nelse:\n    print(\"Columna 'posicion' no disponible; omitiendo simulación de posición.\")\n    "
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# %% [markdown]\n# ## 7. Predicción sobre todo el dataset y chequeo de coherencia\n\npreds_all = pd.DataFrame(index=X.index)\nfor target in targets:\n    preds_all[target] = np.clip(modelos[target].predict(X.values), 0, 100)\n\n# Suma de causas como Total estimado\npreds_all['frr_total_estimado'] = preds_all.sum(axis=1)\n\n# Unimos con datos originales (si existe frr_total real)\nresultado = best_df.copy()\nfor c in preds_all.columns:\n    resultado[f'pred_{c}'] = preds_all[c]\n\n# Si existe frr_total real, comparamos\nif 'frr_total' in resultado.columns:\n    resultado['dif_total'] = resultado['pred_frr_total_estimado'] - resultado['frr_total']\n\nresultado.to_excel(OUTPUT_DIR / 'predicciones_dataset.xlsx', index=False, engine='openpyxl')\nprint('Predicciones exportadas a: salidas_modelo/predicciones_dataset.xlsx')\n\n# Vista rápida\ncols_pred = [c for c in resultado.columns if c.startswith('pred_')]\ntry:\n    display(resultado[cols_pred].head())\nexcept Exception:\n    print(resultado[cols_pred].head())\n    "
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# %% [markdown]\n# ## 8. Guardar modelos entrenados (opcional)\n\nimport pickle\nfor target, model in modelos.items():\n    path = OUTPUT_DIR / f\"rf_{target}.pkl\"\n    with open(path, 'wb') as f:\n        pickle.dump(model, f)\nprint('Modelos guardados en carpeta salidas_modelo/*.pkl')\n    "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n## 9. Notas finales y próximos pasos\n\n- Este cuaderno entrena **Random Forest por causa** con validación k-fold y reporta **MAE / RMSE / R²**.  \n- Las **importancias** (Gini y permutación) ayudan a priorizar parámetros.  \n- Las **simulaciones** permiten ver el efecto de mover **un** parámetro manteniendo los demás fijos.\n\n**Mejoras posibles:**\n1. Probar **XGBoost/LightGBM** (si están disponibles) y comparar contra RF en k-fold.  \n2. Añadir **bandas de predicción** (conformal prediction o cuantiles) para cuantificar incertidumbre con pocos datos.  \n3. Introducir **interacciones**: simulaciones 2D (barrer `presion` y `angulo` juntos) para mapas de calor.  \n4. Postproceso de **coherencia**: si se requiere, reescalar la suma de causas para que no exceda un `Total` objetivo.\n\n> Si deseas, puedo adaptar este cuaderno a tu **app de Streamlit** para subir un Excel semanal y devolver métricas, gráficas y simulaciones con un solo clic.\n    "
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}